{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "from nlpaug.util import Action\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/bert-base-nli-mean-tokens\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/bert-base-nli-mean-tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../datasets/small_dataset_train_bert_bert_cosign.csv')\n",
    "# test= pd.read_csv('datasets/test_ask_fm.csv')\n",
    "# train=train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16572</th>\n",
       "      <td>going to do you if would be the most attractiv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16573</th>\n",
       "      <td>what celebrity do you think would were the mos...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16574</th>\n",
       "      <td>what celebrity do you think might want the for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16575</th>\n",
       "      <td>what celebrity all you think would be thus muc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16576</th>\n",
       "      <td>what celebrity do humans think so love the one...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17567</th>\n",
       "      <td>what do folk to mind about staying a virgin ti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17568</th>\n",
       "      <td>what do you guys thinking over keeping scared ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17569</th>\n",
       "      <td>what makes you men thinking about stayed a vir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17570</th>\n",
       "      <td>what still you fucking think about staying a v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17571</th>\n",
       "      <td>why do you live thinking about staying each vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     q_a  label\n",
       "16572  going to do you if would be the most attractiv...      0\n",
       "16573  what celebrity do you think would were the mos...      0\n",
       "16574  what celebrity do you think might want the for...      0\n",
       "16575  what celebrity all you think would be thus muc...      0\n",
       "16576  what celebrity do humans think so love the one...      0\n",
       "...                                                  ...    ...\n",
       "17567  what do folk to mind about staying a virgin ti...      0\n",
       "17568  what do you guys thinking over keeping scared ...      0\n",
       "17569  what makes you men thinking about stayed a vir...      0\n",
       "17570  what still you fucking think about staying a v...      0\n",
       "17571  why do you live thinking about staying each vi...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train\n",
    "hate=train.head(1000)\n",
    "non_h=train.tail(1000)\n",
    "hate\n",
    "non_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'augmented_qa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\mjahan18\\desktop\\transformer\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3082\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'augmented_qa'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-aef3811a02e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'augmented_qa'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\mjahan18\\desktop\\transformer\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mjahan18\\desktop\\transformer\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3081\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3083\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'augmented_qa'"
     ]
    }
   ],
   "source": [
    "for i in range(len(hate)):\n",
    "    print(hate['augmented_qa'][i], hate['label'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whtype at do you guys thinking type about sttype aying type a virgin till mtype arritype age . 0\n",
      "whgroup at do you guys thinking group about stgroup aying group a virgin till mgroup arrigroup age . 0\n",
      "what do you guys thinking about staying a virgo till marriage . 0\n",
      "what do you guys thinking about staying a virgo the virgin till marriage . 0\n",
      "what do you guys thinking about staying a pure till marriage . 0\n",
      "what do you guys thinking about staying a vestal till marriage . 0\n",
      "what do you guys thinking about staying a virginal till marriage . 0\n",
      "what do you guys thinking about staying a virtuous till marriage . 0\n",
      "what do you guys thinking about staying a virgin boulder clay marriage . 0\n",
      "what do you guys thinking about staying a virgin public treasury marriage . 0\n",
      "what do you guys thinking about staying a virgin trough marriage . 0\n",
      "what do you guys thinking about staying a virgin cashbox marriage . 0\n",
      "what do you guys thinking about staying a virgin money box marriage . 0\n",
      "what do you guys thinking about staying a virgin till matrimony . 0\n",
      "what do you guys thinking about staying a virgin till union . 0\n",
      "what do you guys thinking about staying a virgin till spousal relationship . 0\n",
      "what do you guys thinking about staying a virgin till wedlock . 0\n",
      "what do you guys thinking about staying a virgin till married couple . 0\n",
      "what do you guys thinking about staying a virgin till man and wife . 0\n",
      "what do you guys thinking about staying a virgin till wedding . 0\n",
      "what do you guys thinking about staying a virgin till marriage ceremony . 0\n",
      "iodine cant feel a damn thiodineng 0\n",
      "iodin cant feel a damn thiodinng 0\n",
      "i cant feel a damn thing 0\n",
      "atomic number 53 cant feel a damn thatomic number 53ng 0\n",
      "one cant feel a damn thoneng 0\n",
      "1 cant feel a damn th1ng 0\n",
      "ace cant feel a damn thaceng 0\n",
      "single cant feel a damn thsingleng 0\n",
      "unity cant feel a damn thunityng 0\n",
      "ane cant feel a damn thaneng 0\n",
      "i buzzword feel a damn thing 0\n",
      "i bank feel a damn thing 0\n",
      "i camber feel a damn thing 0\n",
      "i slang feel a damn thing 0\n",
      "i jargon feel a damn thing 0\n",
      "i lingo feel a damn thing 0\n",
      "i argot feel a damn thing 0\n",
      "i patois feel a damn thing 0\n",
      "i vernacular feel a damn thing 0\n",
      "i pious platitude feel a damn thing 0\n",
      "i bevel feel a damn thing 0\n",
      "i chamfer feel a damn thing 0\n",
      "i cant over feel a damn thing 0\n",
      "i tilt feel a damn thing 0\n",
      "i slant feel a damn thing 0\n",
      "i pitch feel a damn thing 0\n",
      "i cant spirit a damn thing 0\n",
      "i cant tone a damn thing 0\n",
      "i cant feeling a damn thing 0\n",
      "i cant flavor a damn thing 0\n",
      "i cant flavour a damn thing 0\n",
      "i cant look a damn thing 0\n",
      "i cant smell a damn thing 0\n",
      "i cant tactile property a damn thing 0\n",
      "i cant experience a damn thing 0\n",
      "i cant find a damn thing 0\n",
      "i cant sense a damn thing 0\n",
      "i cant finger a damn thing 0\n",
      "i cant palpate a damn thing 0\n",
      "i cangstromnt feel angstrom dangstrommn thing 0\n",
      "i cangstrom unitnt feel angstrom unit dangstrom unitmn thing 0\n",
      "i cvitamin ant feel vitamin a dvitamin amn thing 0\n",
      "i cantiophthalmic factornt feel antiophthalmic factor dantiophthalmic factormn thing 0\n",
      "i caxerophtholnt feel axerophthol daxerophtholmn thing 0\n",
      "i cdeoxyadenosine monophosphatent feel deoxyadenosine monophosphate ddeoxyadenosine monophosphatemn thing 0\n",
      "i cadeninent feel adenine dadeninemn thing 0\n",
      "i camperent feel ampere damperemn thing 0\n",
      "i campnt feel amp dampmn thing 0\n",
      "i ctype ant feel type a dtype amn thing 0\n",
      "i cgroup ant feel group a dgroup amn thing 0\n",
      "i cant feel a darn thing 0\n",
      "i cant feel a hoot thing 0\n",
      "i cant feel a red cent thing 0\n",
      "i cant feel a shit thing 0\n",
      "i cant feel a shucks thing 0\n",
      "i cant feel a tinker's damn thing 0\n",
      "i cant feel a tinker's dam thing 0\n",
      "i cant feel a curse thing 0\n",
      "i cant feel a beshrew thing 0\n",
      "i cant feel a bedamn thing 0\n",
      "i cant feel a anathemize thing 0\n",
      "i cant feel a anathemise thing 0\n",
      "i cant feel a imprecate thing 0\n",
      "i cant feel a maledict thing 0\n",
      "i cant feel a goddamn thing 0\n",
      "i cant feel a blasted thing 0\n",
      "i cant feel a blame thing 0\n",
      "i cant feel a blamed thing 0\n",
      "i cant feel a blessed thing 0\n",
      "i cant feel a damned thing 0\n",
      "i cant feel a darned thing 0\n",
      "i cant feel a deuced thing 0\n",
      "i cant feel a goddam thing 0\n",
      "i cant feel a goddamned thing 0\n",
      "i cant feel a infernal thing 0\n",
      "i cant feel a bloody thing 0\n",
      "i cant feel a all-fired thing 0\n",
      "i cant feel a damn matter 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(143066, 143165):\n",
    "    print(non_h['augmented_qa'][i], non_h['label'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sen=[]\n",
    "label=[]\n",
    "scores=0\n",
    "for i in range(3000):\n",
    "\n",
    "    #Sentences we want sentence embeddings for\n",
    "    sentences = [train['original_qa'][i],train['augmented_qa'][i]]\n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "    #Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    #Perform pooling. In this case, mean pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    sentence_embedding_n= sentence_embeddings.numpy()\n",
    "    score=cosine_similarity([sentence_embedding_n[0]],sentence_embedding_n[1:])\n",
    "    scores=scores+score[0][0]\n",
    "    if score[0][0]>.9:\n",
    "        f_sen.append(train['augmented_qa'][i])\n",
    "        label.append(train['label'][i]) \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9296422765910626"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_dict = {'q_a':f_sen,'label':label}\n",
    "# df = pd.DataFrame(my_dict)\n",
    "# df.to_csv('small_dataset_train_backtranslation_bert_cosign.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
